{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "conda create -n tf_env python=3.10 pip -y\n",
    "conda activate tf_env\n",
    "pip install tensorflow==2.17.1 keras==3.5.0 numpy==1.26.4 scipy==1.13.1 seaborn==0.13.2 tensorflow-model-optimization==0.8.0 scikit-plot==0.3.7 tf_keras==2.17.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 15:45:09.320642: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 15:45:09.329233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-22 15:45:09.338855: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-22 15:45:09.341699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 15:45:09.349241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 15:45:09.841935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.1\n",
      "NumPy version: 1.26.4\n",
      "SciPy version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow_model_optimization.python.core.keras.compat import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/pedro/projetoDL/dataset/processado/\"\n",
    "log_path_tmp = \"/home/pedro/projetoDL/log\"\n",
    "save_path = \"/home/pedro/projetoDL/log/exp_20241103170505/3_fold/prunning/\"\n",
    "\n",
    "# Verifica se o diretório existe, se não, cria o diretório\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Carregar os dados\n",
    "Y = np.load(path + 'Y_train_NewApproach_Injected_v2.npz')\n",
    "Y= Y.f.arr_0\n",
    "\n",
    "X = np.load(path + 'X_train_NewApproach_Injected_v2.npz')\n",
    "X = X.f.arr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de x_train: (514647, 44, 116), y_train: (514647,)\n",
      "Tamanho de x_val: (128662, 44, 116), y_val: (128662,)\n",
      "Distribuição em y_train: (array([0, 1]), array([134480, 380167]))\n",
      "Distribuição em y_val: (array([0, 1]), array([33964, 94698]))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configurar o KFold e selecionar o fold 3\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 0\n",
    "\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    fold_no += 1\n",
    "    if fold_no == 3:  # Selecionar o fold 3\n",
    "        x_train, x_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = Y[train_index], Y[val_index]\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Verificar os dados\n",
    "print(f\"Tamanho de x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Tamanho de x_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(\"Distribuição em y_train:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Distribuição em y_val:\", np.unique(y_val, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fold3_path = \"/home/pedro/projetoDL/log/exp_20241103170505/3_fold/fold_n_3_2dconv_fixed.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo reconstruído com sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">116</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20416</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20416</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,306,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m116\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m51,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20416\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20416\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,306,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,359,233</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,359,233\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,359,041</span> (5.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,359,041\u001b[0m (5.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     36\u001b[0m pruning_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mPolynomialDecay(\n\u001b[1;32m     38\u001b[0m         initial_sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m }\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Aplicar pruning ao modelo\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m model_for_pruning \u001b[38;5;241m=\u001b[39m \u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compilar o modelo podado\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model_for_pruning\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     50\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(),\n\u001b[1;32m     51\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:216\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude(to_prune, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`prune_low_magnitude` can only prune an object of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypes: keras.models.Sequential, keras functional model, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.layers.Layer, list of keras.layers.Layer. You passed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    220\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man object of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_prune\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    221\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "loaded_model = load_model(model_fold3_path)\n",
    "\n",
    "# Reconstruir o modelo carregado como Sequential\n",
    "if not isinstance(loaded_model, Sequential):\n",
    "    raise ValueError(\"O modelo carregado não é do tipo `Sequential`.\")\n",
    "\n",
    "# Criar um novo modelo Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Reconstruir as camadas manualmente\n",
    "for layer in loaded_model.layers:\n",
    "    cloned_layer = layer.__class__.from_config(layer.get_config())\n",
    "    model.add(cloned_layer)\n",
    "\n",
    "# Construir o modelo com um input fixo\n",
    "input_shape = loaded_model.input_shape[1:]  # Obtém a forma de entrada\n",
    "model.build(input_shape=(None, *input_shape))\n",
    "\n",
    "# Ajustar os pesos do modelo carregado para o novo modelo\n",
    "model.set_weights(loaded_model.get_weights())\n",
    "\n",
    "# Verificar se o modelo foi reconstruído corretamente\n",
    "print(\"Modelo reconstruído com sucesso!\")\n",
    "print(model.summary())\n",
    "\n",
    "# Configurar pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.5,\n",
    "        begin_step=0,\n",
    "        end_step=1000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Aplicar pruning ao modelo\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compilar o modelo podado\n",
    "model_for_pruning.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinar o modelo podado\n",
    "print(\"Treinando o modelo podado...\")\n",
    "history = model_for_pruning.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=256,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "# Avaliar o modelo podado\n",
    "scores = model_for_pruning.evaluate(x_val, y_val)\n",
    "print(f\"Loss após pruning: {scores[0]}, Acurácia após pruning: {scores[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao aplicar pruning: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.\n",
      "Tipo do modelo: <class 'keras.src.models.sequential.Sequential'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_for_pruning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTipo do modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Compilar o modelo podado\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mmodel_for_pruning\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     78\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(),\n\u001b[1;32m     79\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     80\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Treinar o modelo podado\u001b[39;00m\n\u001b[1;32m     84\u001b[0m model_for_pruning\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     85\u001b[0m     x_train, y_train,\n\u001b[1;32m     86\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39mvalidation_split,\n\u001b[1;32m     87\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     88\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs\n\u001b[1;32m     89\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_for_pruning' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configuração do pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step for pruning\n",
    "batch_size = 256\n",
    "epochs = 2  # Ajuste conforme necessário\n",
    "validation_split = 0.1  # 10% dos dados de treino serão usados como validação\n",
    "\n",
    "num_images = x_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.5,\n",
    "        begin_step=0,\n",
    "        end_step=end_step\n",
    "    )\n",
    "}\n",
    "\n",
    "# Construir modelo Sequential explicitamente\n",
    "model = Sequential([\n",
    "    Conv2D(32, (5, 5), activation='relu', padding='same', input_shape=(44, 116, 1), kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (5, 5), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Carregar pesos do modelo salvo\n",
    "model.load_weights(model_fold3_path)\n",
    "\n",
    "# Criar um modelo podado a partir do modelo explícito\n",
    "try:\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    # Compilar o modelo podado\n",
    "    model_for_pruning.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo podado\n",
    "    model_for_pruning.fit(\n",
    "        x_train, y_train,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Avaliar o modelo podado\n",
    "    scores = model_for_pruning.evaluate(x_val, y_val)\n",
    "    print(f\"Loss após pruning: {scores[0]}, Acurácia após pruning: {scores[1]}\")\n",
    "\n",
    "    # Salvar o modelo podado\n",
    "    model_for_pruning.save(os.path.join(save_path, \"pruned_fold3_model.h5\"))\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Erro ao aplicar pruning: {e}\")\n",
    "    print(f\"Tipo do modelo: {type(model)}\")\n",
    "\n",
    "# Compilar o modelo podado\n",
    "model_for_pruning.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinar o modelo podado\n",
    "model_for_pruning.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Avaliar o modelo podado\n",
    "scores = model_for_pruning.evaluate(x_val, y_val)\n",
    "print(f\"Loss após pruning: {scores[0]}, Acurácia após pruning: {scores[1]}\")\n",
    "\n",
    "# Salvar o modelo podado\n",
    "model_for_pruning.save(os.path.join(save_path, \"pruned_fold3_model.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de x_train: (514647, 44, 116), y_train: (514647,)\n",
      "Tamanho de x_val: (128662, 44, 116), y_val: (128662,)\n",
      "Distribuição em y_train: (array([0, 1]), array([134480, 380167]))\n",
      "Distribuição em y_val: (array([0, 1]), array([33964, 94698]))\n",
      "O modelo carregado é do tipo Sequential.\n",
      "Erro ao aplicar pruning: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.\n",
      "Tipo do modelo: <class 'keras.src.models.sequential.Sequential'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Criar o modelo podado\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     model_for_pruning \u001b[38;5;241m=\u001b[39m \u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro ao aplicar pruning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:216\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude(to_prune, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`prune_low_magnitude` can only prune an object of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypes: keras.models.Sequential, keras functional model, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.layers.Layer, list of keras.layers.Layer. You passed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    220\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man object of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_prune\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    221\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential."
     ]
    }
   ],
   "source": [
    "# Fazer previsões com o modelo podado\n",
    "y_pred_scores = model_for_pruning.predict(x_val)  # Probabilidades\n",
    "y_pred_class = (y_pred_scores > 0.5).astype(int)  # Classificação binária\n",
    "\n",
    "# Salvar os resultados\n",
    "np.savez_compressed(\n",
    "    os.path.join(save_path, \"fold_3_y_val_y_pred_class_y_pred_scores.npz\"),\n",
    "    y_val=y_val,\n",
    "    y_pred_class=y_pred_class,\n",
    "    y_pred_scores=y_pred_scores\n",
    ")\n",
    "\n",
    "# Salvar o modelo podado\n",
    "model_for_pruning.save(os.path.join(save_path, \"pruned_fold3_model.h5\"))\n",
    "\n",
    "# (Opcional) Converter para TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_pruning)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(os.path.join(save_path, \"pruned_fold3_model.tflite\"), \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Modelo podado e resultados salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, average_precision_score\n",
    "from scipy.stats import ks_2samp\n",
    "import scikitplot as skplt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def extract_final_losses(history):\n",
    "    \"\"\"Função para extrair o melhor loss de treino e validação.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    Dicionário contendo o melhor loss de treino e de validação baseado \n",
    "    no menor loss de validação.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = np.argmin(val_loss)\n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    \"\"\"Função para plotar as curvas de erro do treinamento da rede neural.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    A função gera o gráfico do treino da rede e retorna None.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y, y_pred_class, y_pred_scores=None):\n",
    "    accuracy = accuracy_score(y, y_pred_class)\n",
    "    recall = recall_score(y, y_pred_class)\n",
    "    precision = precision_score(y, y_pred_class)\n",
    "    f1 = f1_score(y, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        skplt.metrics.plot_ks_statistic(y, y_pred_scores)\n",
    "        plt.savefig(\"ks_plot.png\")\n",
    "        plt.show()\n",
    "        y_pred_scores = y_pred_scores[:, 1]\n",
    "        auroc = roc_auc_score(y, y_pred_scores)\n",
    "        aupr = average_precision_score(y, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics\n",
    "\n",
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import time\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scikitplot as skplt\n",
    "import gc\n",
    "\n",
    "# Caminho para os arquivos e modelo podado\n",
    "path = \"/home/pedro/projetoDL/dataset/processado/\"\n",
    "tmp_path = \"/home/pedro/projetoDL/log/exp_20241103170505/3_fold/\"\n",
    "load_path = tmp_path\n",
    "save_path = tmp_path + 'prunning/results_pruned/'\n",
    "\n",
    "# Verifica se o diretório existe, se não, cria o diretório\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "file1 = open(save_path + 'TESTE_model_pruned_log.txt', \"a\")\n",
    "\n",
    "# Carregar os dados de teste\n",
    "Y = np.load(path + 'Y_test_Driving_NewApproach_Injected_v2.npz').f.arr_0\n",
    "X = np.load(path + 'X_test_Driving_NewApproach_Injected_v2.npz').f.arr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir 2/3 dos dados\n",
    "X_subset, _, Y_subset, _ = train_test_split(\n",
    "    X, Y, train_size=1/3, stratify=Y, random_state=42  # Stratify para manter a proporção de classes\n",
    ")\n",
    "\n",
    "# Agora X_subset e Y_subset têm 2/3 dos dados originais\n",
    "X = X_subset\n",
    "Y = Y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo podado do fold 3\n",
    "model = load_model(load_path + 'pruned_fold3_model.h5')\n",
    "\n",
    "# Fazer previsões\n",
    "start = time.time()\n",
    "y_pred_scores = model.predict(X)\n",
    "end = time.time()\n",
    "\n",
    "# Tempo de execução\n",
    "print(f\"\\nSubset size: {X.shape[0]}\\n\", file=file1)\n",
    "print(f\"Runtime of the program is {end - start}\", file=file1)\n",
    "\n",
    "total_time = end - start\n",
    "timesample = total_time / y_pred_scores.shape[0]\n",
    "print(f\"us/sample is {timesample * 1000000}\", file=file1)\n",
    "\n",
    "# Gerar as classificações e probabilidades\n",
    "y_pred_class = (y_pred_scores > 0.5).astype(\"int64\")\n",
    "y_pred_scores_0 = 1 - y_pred_scores\n",
    "y_pred_scores = np.concatenate([y_pred_scores_0, y_pred_scores], axis=1)\n",
    "\n",
    "# Calcular métricas de desempenho\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(Y, y_pred_class, y_pred_scores)\n",
    "\n",
    "# Salvar resultados\n",
    "print(f'Results for pruned model: Recall of {recall}; accuracy of {accuracy}; precision of {precision}; f1 of {f1}; auroc of {auroc}; aupr of {aupr}', file=file1)\n",
    "\n",
    "# Plotar e salvar a matriz de confusão\n",
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "subplot = skplt.metrics.plot_confusion_matrix(Y, y_pred_class, normalize=True)\n",
    "subplot.set_ylim(-0.5, 1.5)\n",
    "plt.savefig(save_path + \"conf_matrix_pruned.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plotar e salvar a curva ROC\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y, y_pred_scores[:, 1])\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "sns.set(rc={'figure.figsize': (8, 8)})\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\n",
    "plt.plot(fpr_keras, tpr_keras, marker='.', label='Pruned Model (auc = %0.4f)' % auc_keras)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(save_path + \"plot_roc_pruned.png\")\n",
    "plt.show()\n",
    "\n",
    "# Limpar recursos\n",
    "file1.close()\n",
    "del model\n",
    "time.sleep(3)\n",
    "gc.collect()\n",
    "\n",
    "print(\"Avaliação do modelo podado concluída!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
