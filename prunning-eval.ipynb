{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "import time \n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU está conectada\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        print(f\"Nome da GPU: {gpu.name}\")\n",
    "else:\n",
    "    print(\"Não conectado a uma GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, average_precision_score\n",
    "from scipy.stats import ks_2samp\n",
    "#import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import interp\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def extract_final_losses(history):\n",
    "    \"\"\"Função para extrair o melhor loss de treino e validação.\n",
    "\n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "\n",
    "    Retorno:\n",
    "    Dicionário contendo o melhor loss de treino e de validação baseado\n",
    "    no menor loss de validação.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = np.argmin(val_loss)\n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    \"\"\"Função para plotar as curvas de erro do treinamento da rede neural.\n",
    "\n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "\n",
    "    Retorno:\n",
    "    A função gera o gráfico do treino da rede e retorna None.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y, y_pred_class, y_pred_scores=None):\n",
    "    accuracy = accuracy_score(y, y_pred_class)\n",
    "    recall = recall_score(y, y_pred_class)\n",
    "    precision = precision_score(y, y_pred_class)\n",
    "    f1 = f1_score(y, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        # skplt.metrics.plot_ks_statistic(y, y_pred_scores)\n",
    "        # plt.savefig(\"ks_plot.png\")\n",
    "        # plt.show()\n",
    "        y_pred_scores = y_pred_scores[:, 1]\n",
    "        auroc = roc_auc_score(y, y_pred_scores)\n",
    "        aupr = average_precision_score(y, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics\n",
    "\n",
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/pedro/projetoDL/dataset/processado/\"\n",
    "save_path = \"/home/pedro/projetoDL/log/prunning/fold3/\"\n",
    "\n",
    "# Verifica se o diretório existe, se não, cria o diretório\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Carregar os dados\n",
    "Y = np.load(path + 'Y_train_NewApproach_Injected_v2.npz')\n",
    "Y= Y.f.arr_0\n",
    "\n",
    "X = np.load(path + 'X_train_NewApproach_Injected_v2.npz')\n",
    "X = X.f.arr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configurar o KFold e selecionar o fold 3\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 0\n",
    "\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    fold_no += 1\n",
    "    if fold_no == 3:  # Selecionar o fold 3\n",
    "        x_train, x_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = Y[train_index], Y[val_index]\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Verificar os dados\n",
    "print(f\"Tamanho de x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Tamanho de x_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(\"Distribuição em y_train:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Distribuição em y_val:\", np.unique(y_val, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model for prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "\n",
    "file_name = f'log_modelo_fold3.txt'\n",
    "\n",
    "model_prunned_save_path = \"/home/pedro/projetoDL/log/prunning/fold3/prunned/\"\n",
    "\n",
    "file1 = open(os.path.join(model_prunned_save_path, file_name), \"a\")\n",
    "\n",
    "model = keras.models.load_model(model_prunned_save_path + '3xPrunned.h5')\n",
    "\n",
    "start = time.time()\n",
    "y_pred_scores = model.predict(x_val)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nEvaluate 3xPrunned at GPU\\n\", file=file1)\n",
    "print(f\"Runtime of the program is {end - start}\", file=file1)\n",
    "total_time = end - start\n",
    "timesample = total_time/y_pred_scores.shape[0]\n",
    "print(f\"us/sample is {timesample*1000000}\", file=file1)\n",
    "\n",
    "y_pred_class = (y_pred_scores > 0.5).astype(\"int64\")\n",
    "\n",
    "y_pred_scores2 = y_pred_scores\n",
    "y_pred_scores_0 = 1 - y_pred_scores\n",
    "y_pred_scores = np.concatenate([y_pred_scores_0, y_pred_scores], axis=1)\n",
    "\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_val, y_pred_class, y_pred_scores)\n",
    "\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando Poda Extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Caminho do modelo a ser carregado\n",
    "model_path = \"/home/pedro/projetoDL/log/prunning/fold3/full/fold3_only.h5\"\n",
    "\n",
    "# Carregar o modelo na variável `model`\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# Verificar o resumo do modelo para garantir que foi carregado corretamente\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Poda extrema (99%)\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.80,\n",
    "        final_sparsity=0.99,\n",
    "        begin_step=0,\n",
    "        end_step=100\n",
    "    )\n",
    "}\n",
    "\n",
    "# Envolver o modelo com poda\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compilar o modelo\n",
    "model_for_pruning.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinar o modelo com callbacks de poda\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=256,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Remover wrappers de poda para exportação\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# Salvar como H5 para GPU\n",
    "model_for_export.save(\"model_pruned_gpu.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para TFLite Quantizado para Raspberry Pi\n",
    "def representative_data_gen():\n",
    "    for input_value in x_val[:100]:  # Use algumas amostras\n",
    "        yield [np.expand_dims(input_value, axis=0).astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "quantized_model = converter.convert()\n",
    "\n",
    "# Salvar o modelo TFLite\n",
    "with open(\"model_pruned_quantized_rpi.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avaliando fully prunned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  61/4021 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732500346.486925  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.488148  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.488935  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.490700  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.492047  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.493099  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.493939  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.496166  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.497216  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.498513  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.499854  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.500722  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.502532  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.503586  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.504582  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.505569  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.507367  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.513434  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.515605  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.517562  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.518872  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.520141  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.521828  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.523717  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.525960  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.527680  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.528931  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.530371  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.533558  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.535159  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500346.537081  205171 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4021/4021 [==============================] - 7s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732500352.978079  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.979174  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.981389  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.982331  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.983263  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.984205  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.984981  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.986686  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.987625  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.989912  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.990693  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.991489  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.992616  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.993568  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.994455  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.995333  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500352.996794  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.004855  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.006881  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.007953  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.008997  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.010060  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.011112  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.012193  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.015176  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.016349  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.017468  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.018762  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.020055  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.021922  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1732500353.024082  205157 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "\n",
    "file_name = f'log_modelo_full_prunned.txt'\n",
    "\n",
    "model_prunned_save_path = \"/home/pedro/projetoDL/log/prunning/fold3/FULL-PRUNNED/\"\n",
    "\n",
    "file1 = open(os.path.join(model_prunned_save_path, file_name), \"a\")\n",
    "\n",
    "model = keras.models.load_model(model_prunned_save_path + 'model_pruned_gpu.h5')\n",
    "\n",
    "start = time.time()\n",
    "y_pred_scores = model.predict(x_val)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nEvaluate full prunned at GPU\\n\", file=file1)\n",
    "print(f\"Runtime of the program is {end - start}\", file=file1)\n",
    "total_time = end - start\n",
    "timesample = total_time/y_pred_scores.shape[0]\n",
    "print(f\"us/sample is {timesample*1000000}\", file=file1)\n",
    "\n",
    "y_pred_class = (y_pred_scores > 0.5).astype(\"int64\")\n",
    "\n",
    "y_pred_scores2 = y_pred_scores\n",
    "y_pred_scores_0 = 1 - y_pred_scores\n",
    "y_pred_scores = np.concatenate([y_pred_scores_0, y_pred_scores], axis=1)\n",
    "\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_val, y_pred_class, y_pred_scores)\n",
    "\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
